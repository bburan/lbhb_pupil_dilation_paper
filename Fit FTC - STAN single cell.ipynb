{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbhb.psychometric import CachedStanModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sig = pd.read_csv('psth_sig_cellids.csv')['cellid'].unique()\n",
    "df = pd.read_csv('frequency_tuning_curves_for_bburan.csv')\n",
    "df.columns = [s.replace(' ', '') for s in df.columns]\n",
    "cols = ['pupil', 'frequency', 'ftc_count', 'ftc_time', 'spont_count', 'spont_time']\n",
    "df = pd.wide_to_long(df, cols, 'cellid', 'idx', sep='_').dropna()\n",
    "df['pupil'] -= 1\n",
    "df['frequency'] = np.log(df['frequency'])\n",
    "\n",
    "#mask = df.apply(lambda x: x.name[0] in sig, axis=1)\n",
    "#df = df.loc[mask]\n",
    "\n",
    "sr = df.groupby(['cellid', 'pupil'])[['spont_count', 'spont_time']].first().sort_index()\n",
    "ftc = df.reset_index().set_index(['cellid', 'pupil', 'frequency'])[['ftc_count', 'ftc_time']].sort_index()\n",
    "m = ftc['ftc_time'] > 0\n",
    "ftc = ftc.loc[m]\n",
    "\n",
    "cells = ftc.index.get_level_values('cellid').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CachedStanModel('gaussian_FTC_single_cell.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_data(cell, ftc, sr):\n",
    "    e = ftc.loc[cell].reset_index()\n",
    "    s = sr.loc[cell].reset_index()\n",
    "\n",
    "    n = len(e)\n",
    "    frequency = e['frequency'].values\n",
    "    spike_count = e['ftc_count'].values.astype('i')\n",
    "    sample_time = e['ftc_time'].values\n",
    "    pupil = e['pupil'].values\n",
    "\n",
    "    spont_count = s['spont_count'].values.astype('i')\n",
    "    spont_time = s['spont_time'].values\n",
    "    \n",
    "    return {\n",
    "        'n': n,\n",
    "        'freq': frequency,\n",
    "        'spike_count': spike_count,\n",
    "        'sample_time': sample_time,\n",
    "        'spont_count': spont_count,\n",
    "        'spont_time': spont_time,\n",
    "        'pupil': pupil,\n",
    "    }\n",
    "\n",
    "\n",
    "fits = {}\n",
    "for cell in cells:\n",
    "    data = get_cell_data(cell, ftc, sr)\n",
    "    fits[cell] = model.sampling(data, iter=10000, control={'adapt_delta': 0.99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ftc_model.pkl', 'wb') as fh:\n",
    "    pickle.dump(model, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ftc_fits.pkl', 'wb') as fh:\n",
    "    pickle.dump(fits, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(ax, fit, data):\n",
    "    bf = fit['bf'].mean()\n",
    "    gain = fit['gain'].mean()\n",
    "    bw = fit['bw'].mean()\n",
    "    offset = fit['offset'].mean()\n",
    "\n",
    "    frequency = np.arange(3, 11, 0.1)\n",
    "    l = np.exp(-0.5*np.square((frequency-bf)/bw))\n",
    "    l = offset + gain * l\n",
    "    ax.plot(np.exp(frequency), l, ':', color='orchid', label='Sm. pupil')\n",
    "    ax.axhline(offset, color='orchid')\n",
    "\n",
    "    bf += fit['bf_pupil_delta'].mean()\n",
    "    gain += fit['gain_pupil_delta'].mean()\n",
    "    bw += fit['bw_pupil_delta'].mean()\n",
    "    offset += fit['offset_pupil_delta'].mean()\n",
    "    l = np.exp(-0.5*np.square((frequency-bf)/bw))\n",
    "    l = offset + gain * l\n",
    "    ax.plot(np.exp(frequency), l, ':', color='seagreen', label='Lg. pupil')\n",
    "    ax.axhline(offset, color='seagreen')\n",
    "\n",
    "    pupil = data['pupil']\n",
    "    frequency = data['freq']\n",
    "    evoked_rate = data['spike_count'] / data['sample_time']\n",
    "    spont_rate = data['spont_count'] / data['spont_time']\n",
    "\n",
    "    m_pupil = pupil == 0\n",
    "    ax.plot(np.exp(frequency[m_pupil]), evoked_rate[m_pupil], 'o-', color='orchid')\n",
    "    m_pupil = pupil == 1\n",
    "    ax.plot(np.exp(frequency[m_pupil]), evoked_rate[m_pupil], 'o-', color='seagreen')\n",
    "\n",
    "    ax.axhline(spont_rate[0], color='orchid', ls=':', lw=2)\n",
    "    ax.axhline(spont_rate[1], color='seagreen', ls=':', lw=2)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "f, axes = pl.subplots(10, 12, figsize=(20, 20))\n",
    "\n",
    "for ax, (cell, fit) in zip(axes.ravel(), fits.items()):\n",
    "    data = get_cell_data(cell, ftc, sr)\n",
    "    plot_fit(ax, fit, data)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['bandwidth'].mean(axis=0).mean()\n",
    "fit['bandwidth_mean'].mean(), fit['bandwidth_sd'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av.plot_trace(fit, ['bandwidth_mean', 'bandwidth_sd', 'offset_alpha', 'offset_beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
