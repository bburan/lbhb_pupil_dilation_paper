{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "\n",
    "from support import CachedStanModel\n",
    "from support import get_metric, forest_plot, load_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er.query('significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts = er['count'].groupby(['cellid', 'pupil']).sum()\n",
    "m = spike_counts == 0\n",
    "exclude = spike_counts.loc[m].unstack().index.values.tolist()\n",
    "print(len(rates['sr']), len(rates['sr'].drop(exclude))), print(len(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = load_rates()\n",
    "er = rates['rlf']\n",
    "sr = rates['sr']\n",
    "\n",
    "e = er.reset_index()\n",
    "s = rates['sr'].reset_index()\n",
    "s['cell_index'] = s['cellid'].map(cell_map.get)\n",
    "s = s.set_index(['cell_index', 'pupil']).sort_index()[['count', 'time']].unstack()\n",
    "\n",
    "cells = e['cellid'].unique()\n",
    "cell_map = {c: i+1 for i, c in enumerate(cells)}\n",
    "cell_index = e['cellid'].apply(cell_map.get).values\n",
    "\n",
    "_, indices = np.unique(e[['cellid', 'pupil']].values.tolist(), axis=0, return_index=True)\n",
    "indices = np.r_[indices, [len(e), -1]]\n",
    "data_cell_index = np.array(indices).reshape((-1, 2)) + 1\n",
    "\n",
    "data = {\n",
    "    'n': len(e),\n",
    "    'n_cells': len(cells),\n",
    "    'level': e['level'].values,\n",
    "    'time': e['time'].values,\n",
    "    'count': e['count'].values.astype('i'),\n",
    "    'sr_count': s['count'][0].values.astype('i'),\n",
    "    'sr_count_pupil': s['count'][1].values.astype('i'),\n",
    "    'sr_time': s['time'][0].values,\n",
    "    'sr_time_pupil': s['time'][1].values,\n",
    "    'data_cell_index': data_cell_index,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CachedStanModel('rl_with_sr.stan')\n",
    "#fit = model.sampling(data, iter=2000, control={'adapt_delta': 0.9, 'max_treedepth': 20})\n",
    "fit = model.sampling(data, iter=2000, control={'max_treedepth': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rl_with_sr_fit.pkl', 'wb') as fh:\n",
    "    pickle.dump(model, fh)\n",
    "    pickle.dump(fit, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit, ['sr_mean', 'sr_delta_mean', 'slope_mean', 'slope_delta_mean', 'threshold_mean', 'threshold_delta_mean', 'threshold_delta_sd']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(fit, credible_interval=0.9)\n",
    "summary_95 = az.summary(fit, credible_interval=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = pl.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "cell_metric = get_metric(summary, 'sr_delta_cell', cells=cells)\n",
    "pop_metric = get_metric(summary, 'sr_delta_mean')\n",
    "forest_plot(axes[0], cell_metric, pop_metric, 'sr')\n",
    "\n",
    "cell_metric = get_metric(summary, 'slope_delta_cell', cells=cells)\n",
    "pop_metric = get_metric(summary, 'slope_delta_mean')\n",
    "forest_plot(axes[1], cell_metric, pop_metric, 'slope')\n",
    "\n",
    "cell_metric = get_metric(summary, 'threshold_delta_cell', cells=cells)\n",
    "pop_metric = get_metric(summary, 'threshold_delta_mean')\n",
    "forest_plot(axes[2], cell_metric, pop_metric, 'threshold')\n",
    "\n",
    "f.savefig('rl_sr.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'sr_mean',\n",
    "    'slope_mean',\n",
    "    'threshold_mean',\n",
    "    'sr_delta_mean',\n",
    "    'slope_delta_mean',\n",
    "    'threshold_delta_mean',\n",
    "]\n",
    "summary[cols].to_dataframe().T.to_csv('rl_sr_population_metrics.csv')\n",
    "\n",
    "cols = [\n",
    "    'sr_cell',\n",
    "    'slope_cell',\n",
    "    'threshold_cell',\n",
    "    'sr_delta_cell',\n",
    "    'slope_delta_cell',\n",
    "    'threshold_delta_cell',\n",
    "]\n",
    "\n",
    "index = pd.Index(cells, name='cellid')\n",
    "result = {}\n",
    "for c in cols:\n",
    "    r = summary[c].to_series().unstack('metric')\n",
    "    r.index = index\n",
    "    result[c] = r\n",
    "result = pd.concat(result, names=['coefficient'])\n",
    "result.to_csv('rl_sr_cell_metrics.csv')\n",
    "result['mean'].unstack('coefficient').to_csv('rl_sr_cell_metrics_mean_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_data(e, s, ax):\n",
    "    x = e['level'].tolist()\n",
    "    y = e.eval('count/time').tolist()\n",
    "    #x = [0, 0] + e['level'].tolist()\n",
    "    #y = s.eval('count/time').tolist() + e.eval('count/time').tolist()\n",
    "    #size = np.array(s['time'].tolist() + e['time'].tolist())\n",
    "    #color = s['pupil'].tolist() + e['pupil'].tolist()\n",
    "    #size = 100 * size/size.mean()\n",
    "    color = e['pupil'].tolist()\n",
    "    colors = {0: 'seagreen', 1: 'orchid'}\n",
    "    color = [colors[e] for e in color]\n",
    "    ax.scatter(x, y, 10, color, alpha=0.5)\n",
    "    #ax.plot(x, y, 'o', color=color, alpha=0.5)\n",
    "    \n",
    "\n",
    "def plot_fit(er, sr, fit, cell_map, cell, ax):\n",
    "    c = fit.to_dataframe(diagnostics=False).mean()\n",
    "    level = np.arange(-10, 80)\n",
    "    i = cell_map[cell]\n",
    "\n",
    "    e = er.loc[cell].reset_index()\n",
    "    s = sr.loc[cell].reset_index()\n",
    "    plot_raw_data(e, s, ax)\n",
    "    s = s.set_index('pupil').eval('count/time')\n",
    "    ax.axhline(s.loc[0], ls=':', color='seagreen')\n",
    "    ax.axhline(s.loc[1], ls=':', color='orchid')\n",
    "    \n",
    "    sr = c[f'sr_cell[{i}]']\n",
    "    slope = c[f'slope_cell[{i}]']\n",
    "    threshold = c[f'threshold_cell[{i}]']\n",
    "    sr_pupil_delta = c[f'sr_delta_cell[{i}]']\n",
    "    slope_pupil_delta = c[f'slope_delta_cell[{i}]']\n",
    "    threshold_pupil_delta = c[f'threshold_delta_cell[{i}]']\n",
    "\n",
    "    pred = slope * (level - threshold) + sr\n",
    "    pred[level <= threshold] = sr\n",
    "    pred = np.clip(pred, 0, np.inf)\n",
    "    ax.plot(level, pred, color='seagreen')\n",
    "\n",
    "    sr_pupil = sr + sr_pupil_delta\n",
    "    slope_pupil = slope + slope_pupil_delta\n",
    "    threshold_pupil = threshold + threshold_pupil_delta\n",
    "\n",
    "    pred = slope_pupil * (level - threshold_pupil) + sr_pupil\n",
    "    pred[level <= threshold_pupil] = sr_pupil\n",
    "    pred = np.clip(pred, 0, np.inf)\n",
    "    ax.plot(level, pred, color='orchid')\n",
    "    \n",
    "    \n",
    "f, axes = pl.subplots(5, 5, figsize=(10, 10))\n",
    "for cell, ax in zip(cells, axes.ravel()):\n",
    "    plot_fit(er, sr, fit, cell_map, cell, ax)\n",
    "    i = cell_map[cell] - 1\n",
    "    t = f'{cell}'\n",
    "    #lb, m, ub = np.percentile(fit['threshold_cell'][:, i], [2.5, 50.0, 97.5])\n",
    "    #t = f'{t}\\nTh ({lb:.0f} | {m:.0f} | {ub:.0f})'\n",
    "    #lb, m, ub = np.percentile(fit['threshold_delta_cell'][:, i], [2.5, 50.0, 97.5])\n",
    "    #t = f'{t}\\n$\\Delta$th ({lb:.0f} | {m:.0f} | {ub:.0f})'\n",
    "    ax.set_title(t)\n",
    "    \n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['threshold_sd'].to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_cell = summary['threshold_cell'].to_series().loc['mean']\n",
    "pl.hist(threshold_cell, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
